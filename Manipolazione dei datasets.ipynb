{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bachelor thesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last update: 2024-06-04 at 18.19\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.outliers_influence as smo\n",
    "import statsmodels.stats.diagnostic as smd\n",
    "import statsmodels.stats.stattools as stools\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"kurtosistest only valid for n>=20\")\n",
    "\n",
    "from dwtest import dwtest\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d at %H.%M')\n",
    "print(f\"Last update: {datetime.now().strftime('%Y-%m-%d at %H.%M')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funzioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set working directory\n",
    "Funzione per impostare la cartella di lavoro (e verificare al tempo stesso che esita). In input è sufficiente inserire il percorso della cartella.\n",
    "\n",
    "Esempio: *setwd(path)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setwd(path):\n",
    "    try:\n",
    "        import os\n",
    "        directory = path\n",
    "\n",
    "        # Verifica che il percorso della cartella esista\n",
    "        if os.path.exists(directory):\n",
    "            # Imposta la cartella di lavoro corrente\n",
    "            os.chdir(directory)\n",
    "            #print(f\"\\nCartella di lavoro impostata su: {directory}\")\n",
    "        else:\n",
    "            print(f\"\\nIl percorso della cartella '{directory}' non esiste.\")\n",
    "    except Exception:\n",
    "        print(\"\\nErrore durante l'impostazione della cartella di lavoro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series\n",
    "Funzione per convertire un dataset in una serie storica (R-style). Gli argomenti sono:\n",
    "- data: valori della serie storica;\n",
    "- start: tupla con (primo anno, primo sottoperiodo). Se la serie è su base annuale bisogna comunque inserire (x, 1).\n",
    "- end: tupla con (ultimo anno, ultimo sottoperiodo). Se la serie è su base annuale bisogna comunque inserire (x, 1).\n",
    "- frequency: sottoperiodi dei vari anni (es. semestrale = 2, trimestrale = 4, mensile = 12). Se la serie è su base annuale bisogna comunque inserire frequency = 1.\n",
    "\n",
    "La funzione utilizza la libreria Pandas e restituisce la serie storica in formato Pandas Series (*class 'pandas.core.series.Series'*). \n",
    "\n",
    "NB: La funzione funziona solo con serie storiche su base annuale, semestrale, trimestrale, quadrimestrale, mensile. Non funziona quindi con serie storiche su base giornaliera.\n",
    "\n",
    "Esempio per creare una serie storica con i valori contenuti in *dataset* per il periodo 2024-2025 (su base mensile, a partire da gennaio 2024):    \n",
    "*dataset = list(range(1, 25))*  \n",
    "*timeseries = ts(dataset, (2024, 1), (2025, 12), 12)*   \n",
    "*print(timeseries)* \n",
    "\n",
    "NB: Per fare l'equivalente della funzione *window()* di R è sufficiente usare il metodo *.iloc[\"lower limit\" : \"upper limit\"]* della libreria Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare una time series\n",
    "def ts(data, start, end, frequency):\n",
    "    try:\n",
    "        first_year = start[0]\n",
    "        first_subperiod = start[1]\n",
    "        last_year = end[0]\n",
    "        last_subperiod = end[1]\n",
    "\n",
    "        years = list(range(first_year, (last_year+1)))\n",
    "        times = list()\n",
    "\n",
    "        if frequency == 1: # Annual\n",
    "            times.append(years)\n",
    "        else:\n",
    "            if frequency == 2: # Biannual \n",
    "                for i in range(len(years)):\n",
    "                    times.append(f\"S1/{years[i]}\")\n",
    "                    times.append(f\"S2/{years[i]}\")\n",
    "            else: \n",
    "                if frequency == 3: # Four-month\n",
    "                    for i in range(len(years)):\n",
    "                        times.append(f\"Q1/{years[i]}\")\n",
    "                        times.append(f\"Q2/{years[i]}\")\n",
    "                        times.append(f\"Q3/{years[i]}\")\n",
    "                else:\n",
    "                    if frequency == 4: # Quarterly\n",
    "                        for i in range(len(years)):\n",
    "                            times.append(f\"Q1/{years[i]}\")\n",
    "                            times.append(f\"Q2/{years[i]}\")\n",
    "                            times.append(f\"Q3/{years[i]}\")\n",
    "                            times.append(f\"Q4/{years[i]}\")\n",
    "                    else:\n",
    "                        if frequency == 12: # Monthly\n",
    "                            months = list(range(1,13))\n",
    "                            for i in range(len(years)):\n",
    "                                for j in range(len(months)):\n",
    "                                    times.append(f\"{months[j]}/{years[i]}\")\n",
    "\n",
    "        if first_subperiod != 1:\n",
    "                times = times[first_subperiod - 1:]\n",
    "\n",
    "        if last_subperiod != frequency:\n",
    "            removeindex = frequency - last_subperiod\n",
    "            times = times[:-removeindex]\n",
    "\n",
    "        timeseries = pd.Series(list(data), index = times)\n",
    "\n",
    "        return timeseries\n",
    "    \n",
    "    except Exception:\n",
    "        print(\"Something went wrong. Check that you have entered the parameters correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzione per prendere i dati di bilancio che mi servono\n",
    "Funzione che prende in input i bilanci che ho scaricato da Orbis in formato xlsx ed estrae il ROA, il reddito netto da interessi, il reddito non da interessi, il totale dell'attivo e il margine netto di interesse. Questi dati vengono poi salvati in un nuovo file csv, il quale viene a sua volta salvato nella stessa cartella dove sono stati salvati i bilanci iniziali.    \n",
    "Il parametro *print_report* impostato su *True* serve semplicemente per stampare una stringa se l'esito della funzione è positivo. Di default è impostato su *False*.\n",
    "\n",
    "NB: in input è richiesto il percorso del file dei bilanci, non il nome del file (il quale deve essere \"Financial statement.xlsx\").\n",
    "\n",
    "Esempio:    \n",
    "*getmydata(\"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Banks/14. Unicredit\")*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmydata(path, print_report = False):\n",
    "    try:\n",
    "        # Lettura dei datasets\n",
    "        balance_sheet = pd.read_excel(f\"{path}/Financial statement.xlsx\", sheet_name=\"Stato patrimoniale\")\n",
    "        income_statement = pd.read_excel(f\"{path}/Financial statement.xlsx\", sheet_name=\"Conto economico\")\n",
    "        indices = pd.read_excel(f\"{path}/Financial statement.xlsx\", sheet_name=\"Indici\")\n",
    "        \n",
    "        namebanks = path.split(\"/\")\n",
    "\n",
    "        # Prendo i dati (e gli inverto, i datasets sono 2023 - 2005)\n",
    "        nii = income_statement.iloc[11][::-1] # Net interest income\n",
    "        oi = income_statement.iloc[14][::-1] # Non interest income\n",
    "        prov = income_statement.iloc[20][::-1] # Loan loss provision\n",
    "        assets = balance_sheet.iloc[28][::-1] # Total assets\n",
    "        centralbank = balance_sheet.iloc[25][::-1] # Deposit at Central Bank\n",
    "        roa = indices.iloc[42][::-1] # ROA\n",
    "        int_margin = indices.iloc[36][::-1] # Net interest margin\n",
    "\n",
    "        years = list(range(2005, 2024))\n",
    "\n",
    "        # Creazione di un file riassuntivo\n",
    "        os.chdir(path)\n",
    "        dataset = np.array(list(zip(years, nii, oi, prov, assets, centralbank, roa, int_margin)))\n",
    "\n",
    "        # Creo il nuovo csv\n",
    "        nome_file = \"Financial statement - summary.csv\"\n",
    "        with open(nome_file, 'w', newline ='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Year\", \"Net Interest Income\", \"Non Interest Income\", \"Loan loss provision\", \"Assets\", \"Deposit at Central Bank\", \"ROA\", \"Net Interest Margin\"])\n",
    "\n",
    "            for riga in dataset:\n",
    "                writer.writerow(riga)\n",
    "        \n",
    "        if print_report == True:\n",
    "            print(f\"The file {namebanks[-1]} was created correctly.\")\n",
    "\n",
    "    except Exception:\n",
    "        print(f\"Something went wrong. The file {namebanks[-1]} was not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzione per impostare i livelli di significativa del pvalue\n",
    "La funzione restituisce una lista con dei simboli (R-Style) per vedere ad occhio la significativa dei parametri. È utile quando si va a creare un csv riassuntivo con i parametri dei modelli stimati.\n",
    "\n",
    "Legenda:\n",
    "- 0 <= pavalue <= 0.001: ***\n",
    "- 0.001 < pavalue <= 0.01: **\n",
    "- 0.01 < pavalue <= 0.05: *\n",
    "- 0.05 < pavalue <= 0.1: .\n",
    "- 0.1 < pavalue <= 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_pvalue(pavlue):\n",
    "    try:\n",
    "        levels = list()\n",
    "        for j in range(len(pavlue)):\n",
    "            if (pavlue[j] >= 0) and pavlue[j] <= 0.001:\n",
    "                tmp = \"***\" \n",
    "            else:\n",
    "                if (pavlue[j] > 0.001) and pavlue[j] <= 0.01:\n",
    "                    tmp = \"**\" \n",
    "                else:\n",
    "                    if (pavlue[j] > 0.01) and pavlue[j] <= 0.05:\n",
    "                        tmp = \"*\" \n",
    "                    else:\n",
    "                        if (pavlue[j] > 0.05) and pavlue[j] <= 0.1:\n",
    "                            tmp = \".\" \n",
    "                        else:\n",
    "                            tmp = \" \"\n",
    "            levels.append(tmp)\n",
    "        \n",
    "        return levels \n",
    "    \n",
    "    except Exception:\n",
    "        print(\"Something went wrong. Make sure you have entered a list of p-values.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzione per trasformare un dataset da mensile a annuale\n",
    "Funzione per convertire una serie storica su base mensile in una su base annuale (media annuale). I parametri richiesti sono:\n",
    "- path: percorso (nome incluos) del file contenente la serie storica su base giornaliera\n",
    "- col_date: numero (notazione python) della colonna in cui sono contenute le date\n",
    "- col_numero: numero (notazione python) della colonna in cui sono contenuti i valori\n",
    "- year_index: tupla contentene la prima e l'ultima+1 posizione delò'anno nella stringa delle date (es. se la data è 02/2002 la tupla in year_index sarà (3, 7))\n",
    "- years_range: tupla contentente il primo anno e l'ultimo anno+1 della serie storica (es. se la serie storica va dal 2000 al 2005 la tupla in years_range sarà (2000, 2006))\n",
    "- new_path: nuovo percorso (nome incluso) del file da creare\n",
    "- reverse: condizione boolena per inveritre il dataset (es. l'ultima data diventa la prima, con i relativi valori). Di default è impostato su *False*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mon2ann(path, col_date, col_values, year_index, years_range, new_path, reverse = False):\n",
    "    try:\n",
    "        dataset = np.genfromtxt(path, delimiter=\",\", skip_header=1, dtype=None, encoding=None)\n",
    "\n",
    "        if (reverse == True):\n",
    "            dataset = np.flip(dataset, axis=0)\n",
    "\n",
    "        result = 0\n",
    "        dataset_annual = list()\n",
    "        dataset_times = list()\n",
    "        years = list(range(years_range[0], years_range[1]))\n",
    "        counter = 0\n",
    "\n",
    "        j = 0\n",
    "        i = 0\n",
    "        while i < len(dataset):\n",
    "            if (int(dataset[i][col_date][year_index[0]:year_index[1]]) == int(years[j])):\n",
    "                result = result + float(dataset[i][col_values])\n",
    "                counter = counter + 1\n",
    "                i = i + 1\n",
    "                continue\n",
    "            else:\n",
    "                average = result/counter\n",
    "                dataset_annual.append(average)\n",
    "                dataset_times.append(f\"{dataset[i-1][col_date][year_index[0]:year_index[1]]}\")\n",
    "                counter = 0\n",
    "                result = 0\n",
    "                j = j + 1\n",
    "\n",
    "        average_final = result/counter\n",
    "        dataset_annual.append(average_final)\n",
    "\n",
    "        #Creazione il nuovo file CSV\n",
    "        newdataset = np.array(list(zip(dataset_times, dataset_annual)))\n",
    "\n",
    "        with open(new_path, 'w', newline ='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Times\", \"Value\"])\n",
    "\n",
    "            for riga in newdataset:\n",
    "                writer.writerow(riga)\n",
    "\n",
    "        print(\"The file was created correctly.\")\n",
    "\n",
    "    except Exception:\n",
    "        print(f\"Something went wrong. The file was not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzione per trasformare un dataset da giornaliero a mensile\n",
    "Funzione per convertire una serie storica su base giornaliera in una su base mensile (media mensile). I parametri richiesti sono:\n",
    "- path: percorso (nome incluos) del file contenente la serie storica su base giornaliera\n",
    "- col_date: numero (notazione python) della colonna in cui sono contenute le date\n",
    "- col_numero: numero (notazione python) della colonna in cui sono contenuti i valori\n",
    "- month_index: tupla contentene la prima e l'ultima+1 posizione del mese nella stringa delle date (es. se la data è 02/2002 la tupla in month_index sarà (0, 2))\n",
    "- year_index: tupla contentene la prima e l'ultima+1 posizione delò'anno nella stringa delle date (es. se la data è 02/2002 la tupla in year_index sarà (3, 7))\n",
    "- years_range: tupla contentente il primo anno e l'ultimo anno+1 della serie storica (es. se la serie storica va dal 2000 al 2005 la tupla in years_range sarà (2000, 2006))\n",
    "- new_path: nuovo percorso (nome incluso) del file da creare\n",
    "- reverse: condizione boolena per inveritre il dataset (es. l'ultima data diventa la prima, con i relativi valori). Di default è impostato su *False*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day2mon(path, col_date, col_values, month_index, year_index, years_range, new_path, reverse = False):\n",
    "    try:\n",
    "        dataset = np.genfromtxt(path, delimiter=\",\", skip_header=1, dtype=None, encoding=None)\n",
    "\n",
    "        if (reverse == True):\n",
    "            dataset = np.flip(dataset, axis=0)\n",
    "\n",
    "        month = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "        month = month * (years_range[1] - years_range[0])\n",
    "        result = 0\n",
    "        dataset_monthly = list()\n",
    "        dataset_times = list()\n",
    "        j = 0\n",
    "        counter = 0\n",
    "\n",
    "        i = 0\n",
    "        while i < len(dataset):\n",
    "            if dataset[i][col_date][month_index[0]:month_index[1]] == month[j]:\n",
    "                result = result + dataset[i][col_values]\n",
    "                counter = counter + 1\n",
    "                i = i + 1\n",
    "                continue\n",
    "            else:\n",
    "                average = result/counter\n",
    "                dataset_monthly.append(average)\n",
    "                dataset_times.append(f\"{month[j]}-{dataset[i-1][col_date][year_index[0]:year_index[1]]}\")\n",
    "                counter = 0\n",
    "                result = 0\n",
    "                j = j + 1  \n",
    "\n",
    "        average_final = result/counter\n",
    "        dataset_monthly.append(average_final)\n",
    "\n",
    "        #Creazione il nuovo file CSV\n",
    "        newdataset = np.array(list(zip(dataset_times, dataset_monthly)))\n",
    "\n",
    "        with open(new_path, 'w', newline ='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Times\", \"Value\"])\n",
    "\n",
    "            for riga in newdataset:\n",
    "                writer.writerow(riga)\n",
    "\n",
    "        print(\"The file was created correctly.\")\n",
    "\n",
    "    except Exception:\n",
    "        print(f\"Something went wrong. The file was not created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestione dei datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipolazione dei datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file was created correctly.\n",
      "The file was created correctly.\n"
     ]
    }
   ],
   "source": [
    "# Calcolo della media mensile dei valori del FTSE 100\n",
    "path = \"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Macroeconomics conditions/FTSE 100 - daily.csv\"\n",
    "new_path = \"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Macroeconomics conditions/FTSE 100 - monthly.csv\"\n",
    "day2mon(path, 0, 4, (0,2), (6,8), (1896, 2025), new_path, reverse = True)\n",
    "\n",
    "# Calcolo della media annuale dei valori dell'inflazione europea\n",
    "path = \"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Macroeconomics conditions/EU Inflation - monthly.csv\"\n",
    "new_path = \"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Macroeconomics conditions/EU Inflation - annual.csv\"\n",
    "mon2ann(path, 6, 7, (0,4), (1997, 2025), new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files were created correctly.\n"
     ]
    }
   ],
   "source": [
    "# Prendo i dati di bilancio che mi servono con la funzione scritta prima\n",
    "banks = [\"1. HSBC\",      \n",
    "        \"2. BNP Paribas\",\n",
    "        \"3. Crédit Agricole\",         \n",
    "        \"4. Banco Santander\",\n",
    "        \"5. Barclays\",\n",
    "        \"8. Société Générale\",\n",
    "        \"9. Deutsche Bank\",                   \n",
    "        \"11. Lloyds Banking Group\",            \n",
    "        \"12. Intesa Sanpaolo\",            \n",
    "        \"13. ING Groep\",                   \n",
    "        \"14. UniCredit\",                    \n",
    "        \"15. NatWest Group\",                 \n",
    "        \"16. Standard Chartered\",          \n",
    "        \"18. Banco Bilbao Vizcaya Argentaria\"]\n",
    "\n",
    "for j in range(len(banks)):\n",
    "    getmydata(f\"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Banks/{banks[j]}\")\n",
    "\n",
    "print(\"The files were created correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creazione del panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I datasets mensili hanno tutti lunghezza pari a 216\n",
      "I datasets annuali hanno tutti lunghezza pari a 18\n",
      "All datasets were uploaded correctly.\n"
     ]
    }
   ],
   "source": [
    "setwd(\"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/\")\n",
    "\n",
    "# Upload delle variabili comuni\n",
    "\n",
    "# INTEREST RATES\n",
    "# Euribor - annuale\n",
    "euribor_a_csv = pd.read_csv(\"Interest rate/EURIBOR - annual.csv\")\n",
    "euribor_a = ts(euribor_a_csv.iloc[:,1], (1994, 1), (2024, 1), 1)\n",
    "euribor_a_0623 = euribor_a.loc[2006:2023]\n",
    "# Euribor - mensile\n",
    "euribor_m_csv = pd.read_csv(\"Interest rate/EURIBOR - monthly.csv\")\n",
    "euribor_m = ts(euribor_m_csv.iloc[:,2], (1994, 1), (2024, 2), 12)\n",
    "euribor_m_0623 = euribor_m.loc[\"1/2006\":\"12/2023\"]\n",
    "euribor_m_0623_list = list(euribor_m_0623)\n",
    "# Libor - annuale\n",
    "libor_a_csv = pd.read_csv(\"Interest rate/LIBOR - annual.csv\")\n",
    "libor_a = ts(libor_a_csv.iloc[:,1], (1986, 1), (2023, 1), 1)\n",
    "libor_a_0623 = libor_a.loc[2006:2023]\n",
    "# Libor - mensile\n",
    "libor_m_csv = pd.read_csv(\"Interest rate/LIBOR - monthly.csv\")\n",
    "libor_m = ts(libor_m_csv.iloc[:,2], (1986, 1), (2023, 12), 12)\n",
    "libor_m_0623 = libor_m.loc[\"1/2006\":\"12/2023\"]\n",
    "libor_m_0623_list = list(libor_m_0623)\n",
    "\n",
    "# PENDENZA DELLA CURVA DEI RENDIMENTI\n",
    "# Eurozona \n",
    "# Bond 10y\n",
    "eu_bond10y_csv = pd.read_csv(\"Interest rate/Eurozone Bond 10y - annual.csv\")\n",
    "eu_bond10y = ts(eu_bond10y_csv.iloc[:, 1], (1970, 1), (2023, 1), 1)\n",
    "eu_bond10y = eu_bond10y.loc[2006:2023] \n",
    "# Pendenza \n",
    "eu_slope = eu_bond10y - euribor_a_0623\n",
    "\n",
    "# UK\n",
    "# Bond 10y\n",
    "uk_bond10y_csv = pd.read_csv(\"Interest rate/UK Bond 10y - annual.csv\")\n",
    "uk_bond10y = ts(uk_bond10y_csv.iloc[:, 1], (1986, 1), (2023, 1), 1)\n",
    "uk_bond10y = uk_bond10y.loc[2006:2023] \n",
    "# Pendenza \n",
    "uk_slope = uk_bond10y - libor_a_0623\n",
    "\n",
    "# STOCK MARKET INDEX\n",
    "# FTSE 100 (UK)\n",
    "ftse100_m_csv = pd.read_csv(\"Macroeconomics conditions/FTSE 100 - monthly.csv\")\n",
    "ftse100_m = ts(ftse100_m_csv.iloc[:,1], (1986, 1), (2024, 2), 12)\n",
    "ftse100_m_0623 = ftse100_m.loc[\"1/2006\":\"12/2023\"]\n",
    "# FTSE MIB (ITA)\n",
    "ftsemib_m_csv = pd.read_csv(\"Macroeconomics conditions/FTSE MIB - monthly.csv\")\n",
    "ftsemib_m = ts(ftsemib_m_csv.iloc[:,1], (1997, 12), (2024, 2), 12)\n",
    "ftsemib_m_0623 = ftsemib_m.loc[\"1/2006\":\"12/2023\"]\n",
    "# CAC 40 (FRA)\n",
    "cac40_m_csv = pd.read_csv(\"Macroeconomics conditions/CAC 40 - monthly.csv\")\n",
    "cac40_m = ts(cac40_m_csv.iloc[:,4], (1990, 3), (2024, 3), 12)\n",
    "cac40_m_0623 = cac40_m.loc[\"1/2006\":\"12/2023\"]\n",
    "# DAX (GER)\n",
    "dax_m_csv = pd.read_csv(\"Macroeconomics conditions/DAX - monthly.csv\")\n",
    "dax_m = ts(dax_m_csv.iloc[:,4], (1988, 1), (2024, 3), 12)\n",
    "dax_m_0623 = dax_m.loc[\"1/2006\":\"12/2023\"]\n",
    "# IBEX 35 (SPA)\n",
    "ibex35_m_csv = pd.read_csv(\"Macroeconomics conditions/IBEX 35 - monthly.csv\")\n",
    "ibex35_m = ts(ibex35_m_csv.iloc[:,4], (1993, 8), (2024, 3), 12)\n",
    "ibex35_m_0623 = ibex35_m.loc[\"1/2006\":\"12/2023\"]\n",
    "# AEX (NL)\n",
    "aex_m_csv = pd.read_csv(\"Macroeconomics conditions/AEX - monthly.csv\")\n",
    "aex_m = ts(aex_m_csv.iloc[:,4], (1992, 11), (2024, 4), 12)\n",
    "aex_m_0623 = aex_m.loc[\"1/2006\":\"12/2023\"]\n",
    "\n",
    "# Controlli\n",
    "if len(ftse100_m_0623) == len(ftsemib_m_0623) == len(cac40_m_0623) == len(dax_m_0623) == len(ibex35_m_0623) == len(aex_m_0623) == len(libor_m_0623) == len(euribor_m_0623):\n",
    "    print(f\"I datasets mensili hanno tutti lunghezza pari a {len(libor_m_0623)}\")\n",
    "else:\n",
    "    raise Exception(\"I datasets mensili non hanno tutti la stessa lunghezza.\")\n",
    "\n",
    "if len(libor_a_0623) == len(euribor_a_0623):\n",
    "    print(f\"I datasets annuali hanno tutti lunghezza pari a {len(euribor_a_0623)}\")\n",
    "else:\n",
    "    raise Exception(\"I datasets annuali non hanno tutti la stessa lunghezza.\")\n",
    "\n",
    "print(\"All datasets were uploaded correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I datasets mensili hanno tutti lunghezza pari a 216\n",
      "I datasets annuali hanno tutti lunghezza pari a 18\n",
      "Tutti i file sono stati creati correttamente\n"
     ]
    }
   ],
   "source": [
    "# Creazione del panel\n",
    "banks = [\"1. HSBC\", \"2. BNP Paribas\", \"3. Crédit Agricole\", \"4. Banco Santander\", \"5. Barclays\", \"8. Société Générale\", \"9. Deutsche Bank\", \"11. Lloyds Banking Group\", \"12. Intesa Sanpaolo\", \"13. ING Groep\", \"14. UniCredit\", \"15. NatWest Group\", \"16. Standard Chartered\", \"18. Banco Bilbao Vizcaya Argentaria\"]\n",
    "\n",
    "banks_acronym = [\"hsbc\", \"bnp\", \"aca\", \"sanx\", \"bar\", \"gle\", \"dbk\", \"lloy\", \"isp\", \"inga\", \"ucg\", \"nwg\", \"stan\", \"bbva\"]\n",
    "\n",
    "nation = [\"uk\", \"fra\", \"fra\", \"spa\", \"uk\", \"fra\", \"ger\", \"uk\", \"ita\", \"ned\", \"ita\", \"uk\", \"uk\", \"spa\"]\n",
    "\n",
    "if len(banks) != len(banks_acronym):\n",
    "    raise Exception(\"I vettori banks e banks_acronym hanno lunghezze diverse\")\n",
    "\n",
    "data_fs = pd.DataFrame(columns=[\"Bank\", \"ID\", \"Nation\", \"Years\", \"NII_Assets\", \"OI_Assets\", \"PROV_Assets\", \"DepositCentralBank_Assets\", \"ROA\", \"InterestRate\", \"PendenzaYC\", \"crisis\"])\n",
    "data_sp = pd.DataFrame(columns=[\"Bank\", \"ID\", \"Nation\", \"Times\", \"Stockprice\", \"Stockprice_t0\", \"Stockprice_t1\", \"InterestRate\", \"Market_Index\"])\n",
    "\n",
    "id_fs = list(); id_sp = list(); banks_name_fs = list(); banks_name_sp = list()\n",
    "\n",
    "# Variabile dummy per la crisi\n",
    "years_crisis = list(range(2006,2024))\n",
    "crisis = list()\n",
    "for k in range(len(years_crisis)):\n",
    "    if (years_crisis[k] > 2007) and (years_crisis[k] < 2013):\n",
    "        crisis.append(1)\n",
    "    else:\n",
    "        crisis.append(0)\n",
    "\n",
    "for i in range(len(banks)):\n",
    "    bank = banks[i]\n",
    "    bank_acr = banks_acronym[i]\n",
    "\n",
    "    vars_names = [bank_acr + \"_nii\", bank_acr + \"_oi\", bank_acr + \"_prov\", bank_acr + \"_assets\", bank_acr + \"_dcb\", bank_acr + \"_roa\", \n",
    "                  bank_acr + \"_stockprice\", bank_acr + \"_stockprice_t0\", bank_acr + \"_stockprice_t1\"] # Nomi delle variabili da creare\n",
    "    \n",
    "    fs_csv = pd.read_csv(f\"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Banks/{bank}/Financial statement - summary.csv\") # CSV con i dati di bilancio\n",
    "    sp_csv = pd.read_csv(f\"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/Banks/{bank}/stockprice.csv\") # CSV con i prezzi delle azioni\n",
    "\n",
    "    nii = ts(fs_csv.iloc[:,1], (2005, 1), (2023, 1), 1) # Net interest income (NII)\n",
    "    nii_0623 = nii.loc[2006:2023]\n",
    "\n",
    "    oi = ts(fs_csv.iloc[:,2], (2005, 1), (2023, 1), 1) # Non interest income (OI)\n",
    "    oi_0623 = oi.loc[2006:2023]\n",
    "\n",
    "    prov = ts(fs_csv.iloc[:,3], (2005, 1), (2023, 1), 1) # Loan loss provision (PROV)\n",
    "    prov_0623 = prov.loc[2006:2023]\n",
    "\n",
    "    assets = ts(fs_csv.iloc[:,4], (2005, 1), (2023, 1), 1) # Total assets (ASSETS)\n",
    "    assets_0522 = assets.loc[2005:2022]\n",
    "\n",
    "    dcb = ts(fs_csv.iloc[:,5], (2005, 1), (2023, 1), 1) # Deposit at central bank (DCB)\n",
    "    dcb_0623 = dcb.loc[2006:2023]\n",
    "\n",
    "    roa = ts(fs_csv.iloc[:,6], (2005, 1), (2023, 1), 1)  # ROA\n",
    "    roa_0623 = roa.loc[2006:2023]\n",
    "\n",
    "    dcb_over_assets = [(dcb_0623.iloc[j]/assets_0522.iloc[j])*100 for j in range(len(dcb_0623))]    # Deposit at central bank / total assets * 100\n",
    "    nii_over_assets = [(nii_0623.iloc[j]/assets_0522.iloc[j])*100 for j in range(len(nii_0623))]    # Net interest income / total assets * 100\n",
    "    oi_over_assets = [(oi_0623.iloc[j]/assets_0522.iloc[j])*100 for j in range(len(oi_0623))]       # Non interest income / total assets * 100\n",
    "    prov_over_assets = [(prov_0623.iloc[j]/assets_0522.iloc[j])*100 for j in range(len(prov_0623))] # Loan loss provision / total assets * 100\n",
    "\n",
    "    dcb_0623 = ts(dcb_over_assets, (2006, 1), (2023, 1), 1)\n",
    "    nii_0623 = ts(nii_over_assets, (2006, 1), (2023, 1), 1)\n",
    "    oi_0623 = ts(oi_over_assets, (2006, 1), (2023, 1), 1)\n",
    "    prov_0623 = ts(prov_over_assets, (2006, 1), (2023, 1), 1)\n",
    "\n",
    "    stockprice = ts(sp_csv.iloc[:,4], (2002, 1), (2023,12), 12)\n",
    "    stockprice = stockprice.loc[\"1/2006\":\"12/2023\"] # Stock price\n",
    "    stockprice_t0 = stockprice.loc[\"1/2006\":\"11/2023\"] # Stock price in t0\n",
    "    stockprice_t1 = stockprice.loc[\"2/2006\":\"12/2023\"]# Stock price in t1 \n",
    "\n",
    "    stockprice_list = list(stockprice)\n",
    "    stockprice_t0_list = list(stockprice_t0)\n",
    "    stockprice_t0_list.append(\"NA\")\n",
    "    stockprice_t1_list = list(stockprice_t1)\n",
    "    stockprice_t1_list.insert(0, 'NA')\n",
    "\n",
    "    # Creazione del file\n",
    "    # Indici delle unità osservate\n",
    "    id_fs.append([i+1] * (len(nii_0623)))\n",
    "    id_sp.append([i+1] * (len(stockprice_t1)+1))\n",
    "    banks_name_fs.append([bank_acr] * (len(nii_0623)))\n",
    "    banks_name_sp.append([bank_acr] * (len(stockprice_t1)+1))\n",
    "    # Filtro del tasso di interesse per nazionalità\n",
    "    if nation[i] == \"uk\":\n",
    "        int_rate_a = libor_a_0623\n",
    "        int_rate_m = libor_m_0623_list\n",
    "        pendenza_yc = uk_slope\n",
    "    else:\n",
    "        int_rate_a = euribor_a_0623\n",
    "        int_rate_m = euribor_m_0623_list\n",
    "        pendenza_yc = eu_slope\n",
    "    # Filtro dell'indice di mercato sulla base della nazionalità\n",
    "    if nation[i] == \"ita\":\n",
    "        market_index = ftsemib_m_0623\n",
    "    else:\n",
    "        if nation[i] == \"uk\":\n",
    "            market_index = ftse100_m_0623\n",
    "        else:\n",
    "            if nation[i] == \"fra\":\n",
    "                market_index = cac40_m_0623\n",
    "            else:\n",
    "                if nation[i] == \"spa\":\n",
    "                    market_index = ibex35_m_0623\n",
    "                else:\n",
    "                    if nation[i] == \"ger\":\n",
    "                        market_index = dax_m_0623\n",
    "                    else:\n",
    "                        if nation[i] == \"ned\":\n",
    "                            market_index = aex_m_0623\n",
    "\n",
    "    # Conversione in lista delle serie\n",
    "    int_rate_m_list = list(int_rate_m)\n",
    "    market_index_list = list(market_index)\n",
    "\n",
    "    # Lunghezza della serie storica\n",
    "    years = list(range(2006, 2024))\n",
    "    times = list(stockprice.index)\n",
    "    # Creazione dei datasets\n",
    "    df_fs_tmp = pd.DataFrame({\n",
    "        \"Bank\": banks_name_fs[i],\n",
    "        \"ID\": id_fs[i],\n",
    "        \"Nation\": nation[i],\n",
    "        \"Years\": years,\n",
    "        \"NII_Assets\": nii_0623, \n",
    "        \"OI_Assets\": oi_0623,\n",
    "        \"PROV_Assets\": prov_0623,\n",
    "        \"DepositCentralBank_Assets\": dcb_0623, \n",
    "        \"ROA\": roa_0623,\n",
    "        \"InterestRate\": int_rate_a,\n",
    "        \"PendenzaYC\": list(pendenza_yc),\n",
    "        \"crisis\": crisis\n",
    "    })\n",
    "    data_fs = pd.concat([data_fs, df_fs_tmp], ignore_index=True)\n",
    "\n",
    "    df_sp_tmp = pd.DataFrame({\n",
    "        \"Bank\": banks_name_sp[i],\n",
    "        \"ID\": id_sp[i],\n",
    "        \"Nation\": nation[i],\n",
    "        \"Times\": times,\n",
    "        \"Stockprice\": stockprice_list,\n",
    "        \"Stockprice_t0\": stockprice_t0_list, \n",
    "        \"Stockprice_t1\": stockprice_t1_list, \n",
    "        \"InterestRate\": int_rate_m_list,\n",
    "        \"Market_Index\": market_index_list\n",
    "    })\n",
    "    data_sp = pd.concat([data_sp, df_sp_tmp], ignore_index=True)\n",
    "\n",
    "data_fs.to_csv(\"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/financial_statement_panel.csv\", index=False)  \n",
    "data_sp.to_csv(\"/Users/thomasdemassari/Documents/Università/BSc/Tesi/Data/stock_price_panel.csv\", index=False)\n",
    "\n",
    "# Controlli\n",
    "if len(stockprice) == len(libor_m_0623):\n",
    "    print(f\"I datasets mensili hanno tutti lunghezza pari a {len(libor_m_0623)}\")\n",
    "else:\n",
    "    raise Exception(\"I datasets mensili non hanno tutti la stessa lunghezza.\")\n",
    "\n",
    "if len(nii_0623) == len(nii_0623) == len(prov_0623) == len(assets_0522) == len(dcb_0623) == len(roa_0623) == len(euribor_a_0623):\n",
    "    print(f\"I datasets annuali hanno tutti lunghezza pari a {len(euribor_a_0623)}\")\n",
    "else:\n",
    "    raise Exception(\"I datasets annuali non hanno tutti la stessa lunghezza.\")\n",
    "print(\"Tutti i file sono stati creati correttamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
